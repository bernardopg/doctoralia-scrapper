#!/bin/bash

# Get the directory where this script is located
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
DATA_DIR="$PROJECT_DIR/data"
LOGS_DIR="$PROJECT_DIR/data/logs"

echo "ðŸ” Daily Scraping Results Summary"
echo "================================="
echo ""

# Check recent extractions
echo "ðŸ“Š Recent Data Extractions:"
if [ -d "$DATA_DIR" ]; then
    # Look for JSON files with doctor names
    find "$DATA_DIR" -name "*.json" -type f -printf '%T@ %p\n' | sort -n | tail -5 | while read timestamp file; do
        filename=$(basename "$file")
        if [[ $filename == *"bruna"* ]] || [[ $filename == *"doctor"* ]]; then
            date_str=$(date -d "@${timestamp%.*}" '+%Y-%m-%d %H:%M')
            echo "  âœ… $date_str - $filename"
        fi
    done
else
    echo "  âŒ No data directory found at $DATA_DIR"
fi

echo ""

# Check daily scraping logs
echo "ðŸ“‹ Recent Daily Scraping Logs:"
if [ -f "$LOGS_DIR/scraper.log" ]; then
    echo "  Last 5 entries:"
    tail -5 "$LOGS_DIR/scraper.log" | sed 's/^/    /'
elif [ -f "$LOGS_DIR/daily_scrape.log" ]; then
    echo "  Last 5 entries:"
    tail -5 "$LOGS_DIR/daily_scrape.log" | sed 's/^/    /'
else
    echo "  âŒ No scraping logs found"
fi

echo ""

# Check cron logs
echo "ðŸ¤– Recent Cron Job Logs:"
if [ -f "$LOGS_DIR/cron.log" ]; then
    echo "  Last 3 entries:"
    tail -3 "$LOGS_DIR/cron.log" | sed 's/^/    /'
else
    echo "  âŒ No cron logs found at $LOGS_DIR/cron.log"
fi

echo ""

# Check if cron job is active
echo "â° Cron Job Status:"
if crontab -l 2>/dev/null | grep -q "daily_scrape.sh"; then
    echo "  âœ… Daily scraping cron job is active"
    echo "  ðŸ“ Cron entry(ies):"
    crontab -l | grep "daily_scrape.sh" | sed 's/^/    /'
    # Derive times from cron: prints HH:MM for each entry
    times=$(crontab -l 2>/dev/null | grep "daily_scrape.sh" | awk '{print $2":"$1}' | paste -sd "," -)
    if [ -n "$times" ]; then
        echo "  ðŸ“… Configured times: $times (server local time)"
    fi
else
    echo "  âŒ Daily scraping cron job is not active"
    echo "  ðŸ’¡ Run: ./scripts/manage_daily_cron.sh start"
fi

echo ""

# Check system resources
echo "ðŸ’» System Resources:"
if command -v free >/dev/null 2>&1; then
    echo "  Memory usage:"
    free -h | grep -E "^(Mem|Swap)" | sed 's/^/    /'
fi

if command -v df >/dev/null 2>&1; then
    echo "  Disk usage:"
    df -h "$PROJECT_DIR" | tail -1 | sed 's/^/    /'
fi

echo ""

# Check for any error files
echo "ðŸš¨ Error Files:"
if [ -d "$LOGS_DIR" ]; then
    error_files=$(find "$LOGS_DIR" -name "*error*" -o -name "*fail*" -type f 2>/dev/null | wc -l)
    if [ "$error_files" -gt 0 ]; then
        echo "  âš ï¸ Found $error_files error log files"
        find "$LOGS_DIR" -name "*error*" -o -name "*fail*" -type f 2>/dev/null | sed 's/^/    /'
    else
        echo "  âœ… No error files found"
    fi
